{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.093791700Z",
     "start_time": "2023-12-18T17:30:00.896437400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 18:30:01.139935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-18 18:30:01.140003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-18 18:30:01.140650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-18 18:30:01.144686: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 18:30:01.732977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from pennylane import AngleEmbedding, StronglyEntanglingLayers, RandomLayers\n",
    "import pennylane as qml\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.217366400Z",
     "start_time": "2023-12-18T17:30:03.095791600Z"
    }
   },
   "id": "d65e395ea05d480c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x_train = x_train[:10_000]\n",
    "y_train = y_train[:10_000]\n",
    "\n",
    "x_test = x_test[:1_000]\n",
    "y_test = y_test[:1_000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.222366500Z",
     "start_time": "2023-12-18T17:30:03.220367700Z"
    }
   },
   "id": "7416888ca1166db8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "y_test = y_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.233445800Z",
     "start_time": "2023-12-18T17:30:03.222366500Z"
    }
   },
   "id": "bf7de7753308ea8a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 18:30:03.424262: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.446295: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.446355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.448940: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.448998: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.449032: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.613781: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.613869: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.613878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 18:30:03.613929: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 18:30:03.613950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7551 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.expand_dims(x_train, axis=-1)\n",
    "x_test = tf.expand_dims(x_test, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.879858400Z",
     "start_time": "2023-12-18T17:30:03.287403900Z"
    }
   },
   "id": "40739bf8a8bd0089"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.884856Z",
     "start_time": "2023-12-18T17:30:03.879858400Z"
    }
   },
   "id": "67b146f89da66ac6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "channel_size = 3\n",
    "num_qubits = 9 # use 3 x 3 qubits for kernel "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.888855800Z",
     "start_time": "2023-12-18T17:30:03.885856100Z"
    }
   },
   "id": "66930e1f240795e4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class QuantumConvLayer(Layer):\n",
    "    def __init__(self, filter, circuit_length, padding_mode: str, **kwargs):\n",
    "        super(QuantumConvLayer, self).__init__(**kwargs)\n",
    "        self.filter = filter\n",
    "        self.circuit_length = circuit_length\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num_qubits = input_shape[-1] * 4\n",
    "        self.device = qml.device(\"lightning.qubit\", wires=self.num_qubits)\n",
    "        \n",
    "        @qml.simplify\n",
    "        @qml.qnode(self.device, interface=\"tf\")\n",
    "        def quantum_conv_circuit(inputs, weights):\n",
    "            AngleEmbedding(inputs, wires=range(self.num_qubits))\n",
    "            RandomLayers(weights, wires=range(self.num_qubits))\n",
    "\n",
    "            return qml.expval(qml.PauliZ(wires=0))\n",
    "\n",
    "        \n",
    "        quanv_circ = [qml.qnn.KerasLayer(quantum_conv_circuit, {\"weights\": (self.circuit_length, self.num_qubits)}, output_dim=1) for _ in range(self.filter)]\n",
    "        \n",
    "        outputs = []\n",
    "        input_layer = keras.Input(self.num_qubits)\n",
    "        for layer in quanv_circ:\n",
    "            layer.trainable = True\n",
    "            outputs.append(layer(input_layer))\n",
    "            \n",
    "        output = keras.layers.Concatenate(axis=-1)(outputs)\n",
    "        \n",
    "        self.filter_stage = keras.Model(inputs=input_layer, outputs=output, name=\"filter_stage\")\n",
    "        \n",
    "    @tf.function\n",
    "    def apply_on_batch(self, inputs):\n",
    "        \n",
    "        return self.filter_stage(inputs)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):      \n",
    "        \n",
    "        patches = tf.image.extract_patches(\n",
    "            images=inputs,\n",
    "            sizes=[1, 2, 2, 1],\n",
    "            strides=[1, 1, 1, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=self.padding_mode\n",
    "        )\n",
    "        patches_flat = tf.reshape(patches, [tf.shape(patches)[0], patches.shape[1] * patches.shape[2], patches.shape[3]])\n",
    "        \n",
    "        output = tf.map_fn(self.apply_on_batch, patches_flat, dtype=tf.float32)\n",
    "        #output = self.conv_stage(patches_flat)\n",
    "        output_shape = tf.shape(inputs)\n",
    "        \n",
    "        output = tf.reshape(output, [output_shape[0], output_shape[1], output_shape[2], self.filter])\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.896897400Z",
     "start_time": "2023-12-18T17:30:03.891897200Z"
    }
   },
   "id": "929acead4a560063"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Conv2D(3, 3, strides=(2, 2), activation=\"linear\"),\n",
    "        QuantumConvLayer(6, 2, \"SAME\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:03.923932700Z",
     "start_time": "2023-12-18T17:30:03.895896600Z"
    }
   },
   "id": "32027550e935df04"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alex/miniconda3/envs/fyc_quantum/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _gcd_import at 0x7f7bd8fd7400> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function _gcd_import at 0x7f7bd8fd7400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _gcd_import at 0x7f7bd8fd7400> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function _gcd_import at 0x7f7bd8fd7400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 18:30:27.159185: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-18 18:30:27.228036: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-18 18:30:28.274936: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "_ = model(np.random.random((1, 28, 28, 1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:31.910162600Z",
     "start_time": "2023-12-18T17:30:03.917928300Z"
    }
   },
   "id": "e9be3bfb98e51fe"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (1, 13, 13, 3)            30        \n",
      "                                                                 \n",
      " quantum_conv_layer (Quantu  (1, 13, 13, 6)            144       \n",
      " mConvLayer)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (1, 1014)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (1, 16)                   16240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, 10)                   170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16584 (64.78 KB)\n",
      "Trainable params: 16584 (64.78 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:31.928259200Z",
     "start_time": "2023-12-18T17:30:31.911161Z"
    }
   },
   "id": "a0f3497a4c99a9be"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:31.944554300Z",
     "start_time": "2023-12-18T17:30:31.928259200Z"
    }
   },
   "id": "a5c9f83382ffdef7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer, loss=loss_fn, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T17:30:31.952068Z",
     "start_time": "2023-12-18T17:30:31.934666Z"
    }
   },
   "id": "216e97a6d798b956"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f7b0f472440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f7b0f472440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 18:30:47.286434: I external/local_xla/xla/service/service.cc:168] XLA service 0x2e667bb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-18 18:30:47.286469: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702920647.327727   26604 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 204/2500 [=>............................] - ETA: 7:45:38 - loss: 2.3064 - sparse_categorical_accuracy: 0.1201"
     ]
    }
   ],
   "source": [
    "fitting = model.fit(x_train, y_train, epochs=10, batch_size=4, verbose=1, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-18T17:30:31.950068100Z"
    }
   },
   "id": "c6f6a8d65b6af34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7d1867d963e853b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
